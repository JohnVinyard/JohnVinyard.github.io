
        <!DOCTYPE html>
            <html lang="en">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <meta http-equiv="X-UA-Compatible" content="ie=edge">
                <title>Toward a Sparse Interpretable Audio Codec</title>
                <link rel="preconnect" href="https://fonts.googleapis.com">
                <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
                <link href="https://fonts.googleapis.com/css2?family=Gowun+Batang:wght@400;700&display=swap" rel="stylesheet">
                <script src="https://cdn.jsdelivr.net/gh/JohnVinyard/web-components@v0.0.13/build/components/bundle.js"></script>
                <style>
                    body {
                        font-family: "Gowun Batang", serif;
                        margin: 5vh 5vw;
                        color: #333;
                        background-color: #f0f0f0;
                        font-size: 1.1em;
                    }
                    .back-to-top {
                        position: fixed;
                        bottom: 20px;
                        right: 20px;
                        background-color: #333;
                        color: #f0f0f0;
                        padding: 10px;
                        font-size: 0.9em;
                    }
                    img.full-width {
                        width: 100%;
                    }
                    ul {
                        list-style-type: none;
                        padding-inline-start: 20px;
                        font-size: 20px;
                    }
                    a {
                        color: #660000;
                    }
                    a:visited {
                        color: #000066;
                    }
                    caption {
                        text-decoration: underline;
                        font-size: 0.6em;
                    }
                    blockquote {
                        background-color: #d5d5d5;
                        padding: 2px 10px;
                    }
                </style>
            </head>
            <body>
                
    <h1>Toward a Sparse Interpretable Audio Codec</h1>
<details>
    <summary>
        <caption>Table of Contents</caption>
    </summary>

<ul>
<li><a href="#Introduction">Introduction</h1></a></li>
<li><a href="#Previous Work">Previous Work</h1></a></li>
<li><a href="#Model">Model</h1></a><ul>
<li><a href="#Encoder">Encoder</h2></a></li>
<li><a href="#Decoder">Decoder</h2></a></li>
</ul>
</li>
<li><a href="#Training Procedure">Training Procedure</h1></a></li>
<li><a href="#Streaming Algorithm">Streaming Algorithm</h1></a></li>
<li><a href="#Future Work">Future Work</h1></a><ul>
<li><a href="#Better Perceptual Audio Losses">Better Perceptual Audio Losses</h2></a></li>
<li><a href="#Model Size, Training Time and Dataset">Model Size, Training Time and Dataset</h2></a></li>
<li><a href="#Different Event Generator Variants">Different Event Generator Variants</h2></a></li>
</ul>
</li>
<li><a href="#Cite this Article">Cite this Article</h1></a></li>
<li><a href="#Streaming Algorithm for Arbitrary-Length Audio Segments">Streaming Algorithm for Arbitrary-Length Audio Segments</h1></a><ul>
<li><a href="#Original (Streaming)">Original (Streaming)</h2></a></li>
<li><a href="#Reconstruction (Streaming)">Reconstruction (Streaming)</h2></a></li>
</ul>
</li>
<li><a href="#Audio Examples">Audio Examples</h1></a><ul>
<li><a href="#Example 1">Example 1</h2></a></li>
<li><a href="#Example 2">Example 2</h2></a></li>
<li><a href="#Example 3">Example 3</h2></a></li>
<li><a href="#Example 4">Example 4</h2></a></li>
<li><a href="#Example 5">Example 5</h2></a></li>
</ul>
</li>
<li><a href="#Notes">Notes</h1></a></li>
</ul>
</details>
                
<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event0_08780d23e016823ed01b8a941ecad02a963e9b0a"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event1_8d448baf7cdc0a1fd58973e0ad22f2faf1cf7b12"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event2_bd7aa478640fb09f7c0bb34f6e5003b83f5413d4"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event3_8d5f7e6d0eeccd8c756739dda9adbb23b090121e"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event4_097287a71f4688b70aed15012a68b5885cb060c3"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event5_3cdc562210717a4b8126147250370eaa9f99bdb4"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event6_14ad56e675dc1e26e0f53da92c45343ce6d54717"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event7_bcd2ad95dd02edb91c4fa9f443a09156bdf5e455"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event8_8a38092e1bbc41c08993eea23254e82308290906"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event9_297f7ac251b8b5a730cbe713e718b09f9c55188f"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event10_ba526cc17be57f4b431b2df165a1732e1844001d"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event11_0bbfe68f60067e51048137c645414b041637942c"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event12_f3234476c5e21c2608f09341f0705a4d11b087a2"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event13_7520efbb3b32049fde29f502aefe9f7db8f7aae3"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event14_9a0a9bc82a71d63f4eeba4b1fae0c31759fd768f"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event15_8da208fb7dad0e6c7d26e647accd7abe416c2823"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event16_ff54b91c2082e97a26ba853b8e2b2f3da57355bb"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event17_300381dcb0ab038050c8ee6103d9ba3e59e31e7d"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event18_92b07b7c8e9bb6bb5e362a5a4a3b085060eec938"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event19_6fe24d0696e870d8e8b8cbf92587eecde0b87dec"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event20_3974f1c21ad059f1393d9a5fd9127e190138106d"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event21_ebda11ad2f0a3664495072239f8a1c92dc2c9091"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event22_70f6e8f6e96d408d2c10751b8703b50359d9e0ad"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event23_d871998b34fc1a41f803c9c59f96b361132eb3d7"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event24_f6d2eb667d68f9dd7b750279b082438e3483c170"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event25_2268ca3646827b85bd29d6d474a8376fa3cbe1f5"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event26_f70e4fe8a4cdef9c9b9a7173810bc83b94028786"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event27_d57d7f050e1deb47d9ef1b334624b1848e403097"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event28_4f500473f2c9b149be53f2c10e8abc3ce0c829a6"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event29_c2f7f68e6aeaaff770ed7d878741f93c125cf61c"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event30_2d770e69c190fde23ca4f1b55def2720c996b5a1"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/event31_74fb967c198e333c608fcb34ccb6a1970ed0399a"
            height="15"
            samples="256"
            scale="1"
            
        ></audio-view>


<a id="Introduction"></a>
<h1>Introduction</h1>
<p>Most widely-used modern audio codecs, such as Ogg Vorbis and MP3, as well as more recent "neural" codecs like
<a href="https://arxiv.org/abs/2210.13438">Meta's Encodec</a> or <a href="https://arxiv.org/abs/2306.06546">Descript's</a> are based on
block-coding;  audio is divided into overlapping, fixed-size "frames" which are then compressed.  While they produce
excellent reproduction quality and can be used for downstream tasks such as text-to-audio, they do not produce an
intuitive, directly-interpretable representation.</p>
<p>In this work, we introduce a proof-of-concept audio encoder that seeks to encode audio as a sparse set of events and
their times-of-occurrence.  Rudimentary physics-based assumptions are used to model attack and the physical resonance
of both the instrument being played and the room in which a performance occurs, hopefully encouraging a sparse,
parsimonious, and easy-to-interpret representation.</p>

<a id="Previous Work"></a>
<h1>Previous Work</h1>
<p>This work takes inspiration from symbolic approaches, such as MIDI, iterative decomposition methods like matching pursuit
and granular synthesis, which represents audio as a sparse set of "grains" or simple audio atoms.</p>

<a id="Model"></a>
<h1>Model</h1>

<a id="Encoder"></a>
<h2>Encoder</h2>
<p>The encoder iteratively removes energy from the input spectrogram, producing an event vector and one-hot/dirac impulse
representing the time of occurrence.</p>

<a id="Decoder"></a>
<h2>Decoder</h2>
<p>The decoder uses the 32-dimensional event vector to choose an attack envelope, evolving resonance, and room impulse
response to model the acoustic event, and then "schedules" it by convolving the event with the one-hot/direc impulse.  Audio
is not produced using typical upsampling convolutions, avoiding artifacts and producing more natural-sounding events.</p>

<a id="Training Procedure"></a>
<h1>Training Procedure</h1>
<p>We train on the <a href="https://zenodo.org/records/5120004#.Yhxr0-jMJBA">MusicNet dataset</a> dataset) for ~48 hours, selecting
random ~6 second audio segments sampled at 22050hz (mono) with a batch-size of 2.  The model takes the following steps
for 32 iterations on each training sample:</p>
<ol>
<li>The encoder analyzes the STFT spectrogram of the signal, producing a single 32-dimensional event vector and a one-hot vector representing time-of-occurrence</li>
<li>The decoder produces "raw" audio samples of the acoustic event</li>
<li>an STFT spectrogram of the acoustic event is produced and subtracted from the input spectrogram</li>
<li>The encoder analyzes the residual and the process is repeated</li>
</ol>
<p>The model is trained to maximize the amount of energy removed from the original signal at each step, and to minimize
an adversarial loss, produced by a small, convolutional down-sampling discriminator which is trained in parallel,
analyzing both the real and reproduced signals in the STFT spectrogram domain.  Half of the generated events are
masked/removed when analyzed by the discriminator, encouraging each event vector to stand on its own as a realistic
event.</p>
<p>All training and model code can be
<a href="https://github.com/JohnVinyard/matching-pursuit/blob/main/iterativedecomposition.py">found here</a>.</p>

<a id="Streaming Algorithm"></a>
<h1>Streaming Algorithm</h1>
<p>When encoding, the entire ~6-second spectrogram is analyzed, but its second-half is masked when choosing the next event.
In this way, the model can slide along overlapping sections of audio and encode segments of arbitrary durations.</p>

<a id="Future Work"></a>
<h1>Future Work</h1>

<a id="Better Perceptual Audio Losses"></a>
<h2>Better Perceptual Audio Losses</h2>
<p>Recent experiments use a greedy, per-event loss which maximizes the energy removed from the signal at each step, as well
as a learned, adversarial loss.  Reconstruction quality will likely benefit from a more perceptually-aligned loss and a
larger, more diverse dataset.</p>

<a id="Model Size, Training Time and Dataset"></a>
<h2>Model Size, Training Time and Dataset</h2>
<p>Firstly, this model is relatively small, weighing in at ~14M parameters (~80 MB on disk) and has only been trained for
around 48 hours, so it seems there is a lot of space to increase the model size, dataset size and training time to
further improve.  The reconstruction quality of the examples on this page is not amazing, certainly not good enough
even for a lossy audio codec, but the structure the model extracts seems like it could be used for many interesting
applications.  The training data should be expanded beyond the MusicNet dataset.</p>

<a id="Different Event Generator Variants"></a>
<h2>Different Event Generator Variants</h2>
<p>The decoder side of the model is very interesting, and all sorts of physical modelling-like approaches could yield
better, more realistic, and sparser renderings of the audio.</p>


<a id="Cite this Article"></a>
<h1>Cite this Article</h1>
<p>If you'd like to cite this article, you can use the following <a href="https://bibtex.org/">BibTeX block</a>.</p>

<citation-block
            tag="johnvinyarditerativedecompositionv3"
            author="Vinyard, John"
            url="https://blog.cochlea.xyz/sparse-interpretable-audio-codec-paper.html"
            header="Toward a Sparse Interpretable Audio Codec"
            year="2025">
        </citation-block>


<a id="Streaming Algorithm for Arbitrary-Length Audio Segments"></a>
<h1>Streaming Algorithm for Arbitrary-Length Audio Segments</h1>
<p>In this latest iteration of the work, we introduce a "streaming" algorithm so that we can decompose audio segments of
arbitrary lengths.</p>


<a id="Original (Streaming)"></a>
<h2>Original (Streaming)</h2>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/streamingorig_384ef9dda1601c1707330b141d12eab4d08b390e"
            height="100"
            samples="256"
            scale="4"
            controls
        ></audio-view>


<a id="Reconstruction (Streaming)"></a>
<h2>Reconstruction (Streaming)</h2>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/streamingrecon_44bfad9faef7c94e9ff189bd3eed8e421902167d"
            height="100"
            samples="256"
            scale="4"
            controls
        ></audio-view>


<a id="Audio Examples"></a>
<h1>Audio Examples</h1>


<a id="Example 1"></a>
<h2>Example 1</h2>


<a id="Original Audio"></a>
<h3>Original Audio</h3>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/original_ee948d06cf1505f4610aedfcc78ddab65752d61a"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Reconstruction"></a>
<h3>Reconstruction</h3>
<p>We mask the second half of the input audio to enable the streaming algorithm, so only the first half of the input audio is reproduced.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/reconstruction_062c1e95d1061ace8909deba02d17bad59980462"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Decomposition"></a>
<h3>Decomposition</h3>
<p>We can see that while energy is removed at each step, removed segments do not map cleanly onto audio "events" as a human listener would typically conceive of them.  Future work will move toward fewer and more meaningul events via induced sparsity and/or clustering of events.</p>

<img class="full-width" src="https://iterative-decomposition-v3.s3.amazonaws.com/decomposition_8937216c702b29407e4a32771d8e5aa1ffca0489" height="200"></img>


<a id="Randomized"></a>
<h3>Randomized</h3>

<p>Here, we generate random event vectors with the original event times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedevents_00bff5e7cd8fa1340fddcf7659199148993e99e3"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>

<p>Here we use the original event vectors, but generate random times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedtimes_18f61bf7031ab782e244f49ca624619c7fb7e84c"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Event Vectors"></a>
<h3>Event Vectors</h3>
<p>Different stopping conditions might be chosen during inference (e.g. norm of the residual) but during training, we remove energy for 32 steps.  Each event vector is of dimension 32.  The decoder generates an event from this vector, which is then scheduled.  </p>

<img class="" src="https://iterative-decomposition-v3.s3.amazonaws.com/latents_d224846f75817232b17a629ff038c1fe48434232" height="200"></img>


<a id="Event Scatterplot"></a>
<h3>Event Scatterplot</h3>
<p>Time is along the x-axis, and a 32D -&gt; 1D projection of event vectors using t-SNE constitutes the distribution along the y-axis.  Colors are produced via a random projection from 32D -&gt; 3D (RGB).  Here it becomes clear that there are many redundant/overlapping events.  Future work will stress more sparsity and less event overlap, hopefully increasing interpretability further.</p>

<scatter-plot 
                width="600" 
                height="300" 
                radius="0.01" 
                points='[{"x": 5.064087390899658, "y": 0.12890624575447873, "startSeconds": 0.7662584781646729, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event0_08780d23e016823ed01b8a941ecad02a963e9b0a", "color": "rgb(98 179 50)"}, {"x": 5.053908824920654, "y": 0.1328124938027031, "startSeconds": 0.7894784212112427, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event1_8d448baf7cdc0a1fd58973e0ad22f2faf1cf7b12", "color": "rgb(79 156 34)"}, {"x": 5.117682933807373, "y": 0.1328124938027031, "startSeconds": 0.7894784212112427, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event2_bd7aa478640fb09f7c0bb34f6e5003b83f5413d4", "color": "rgb(65 144 29)"}, {"x": 5.013785362243652, "y": 0.16601562226696842, "startSeconds": 0.9868480563163757, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event3_8d5f7e6d0eeccd8c756739dda9adbb23b090121e", "color": "rgb(136 201 85)"}, {"x": 5.050158977508545, "y": 0.1679687462910806, "startSeconds": 0.9984580278396606, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event4_097287a71f4688b70aed15012a68b5885cb060c3", "color": "rgb(122 199 76)"}, {"x": 5.322775363922119, "y": 0.18554687253526936, "startSeconds": 1.1029478311538696, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event5_3cdc562210717a4b8126147250370eaa9f99bdb4", "color": "rgb(52 114 33)"}, {"x": 5.554961681365967, "y": 0.2050781127763912, "startSeconds": 1.2190475463867188, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event6_14ad56e675dc1e26e0f53da92c45343ce6d54717", "color": "rgb(111 213 85)"}, {"x": 5.514759540557861, "y": 0.2050781127763912, "startSeconds": 1.2190475463867188, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event7_bcd2ad95dd02edb91c4fa9f443a09156bdf5e455", "color": "rgb(88 191 56)"}, {"x": 5.15139102935791, "y": 0.23437500321961124, "startSeconds": 1.3931972980499268, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event8_8a38092e1bbc41c08993eea23254e82308290906", "color": "rgb(76 159 38)"}, {"x": 5.346749782562256, "y": 0.2402343652647687, "startSeconds": 1.4280271530151367, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event9_297f7ac251b8b5a730cbe713e718b09f9c55188f", "color": "rgb(48 141 34)"}, {"x": 4.713881015777588, "y": 0.21484374292413122, "startSeconds": 1.277097463607788, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event10_ba526cc17be57f4b431b2df165a1732e1844001d", "color": "rgb(135 254 56)"}, {"x": 5.959319591522217, "y": 0.08984374521787686, "startSeconds": 0.5340589284896851, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event11_0bbfe68f60067e51048137c645414b041637942c", "color": "rgb(36 154 37)"}, {"x": 5.626179218292236, "y": 0.06835937593905328, "startSeconds": 0.40634921193122864, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event12_f3234476c5e21c2608f09341f0705a4d11b087a2", "color": "rgb(68 166 39)"}, {"x": 5.4876484870910645, "y": 0.003906249928320449, "startSeconds": 0.02321995422244072, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event13_7520efbb3b32049fde29f502aefe9f7db8f7aae3", "color": "rgb(65 158 47)"}, {"x": 5.600058078765869, "y": 0.003906249928320449, "startSeconds": 0.02321995422244072, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event14_9a0a9bc82a71d63f4eeba4b1fae0c31759fd768f", "color": "rgb(50 156 54)"}, {"x": 5.753261566162109, "y": 0.005859374579131327, "startSeconds": 0.03482992947101593, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event15_8da208fb7dad0e6c7d26e647accd7abe416c2823", "color": "rgb(43 154 45)"}, {"x": 5.680963516235352, "y": 0.27148436970492185, "startSeconds": 1.6137868165969849, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event16_ff54b91c2082e97a26ba853b8e2b2f3da57355bb", "color": "rgb(53 158 59)"}, {"x": 5.70194149017334, "y": 0.2910156099460437, "startSeconds": 1.729886531829834, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event17_300381dcb0ab038050c8ee6103d9ba3e59e31e7d", "color": "rgb(74 226 55)"}, {"x": 5.8235626220703125, "y": 0.29296874399733497, "startSeconds": 1.7414965629577637, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event18_92b07b7c8e9bb6bb5e362a5a4a3b085060eec938", "color": "rgb(48 204 30)"}, {"x": 5.792729377746582, "y": 0.005859374579131327, "startSeconds": 0.03482992947101593, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event19_6fe24d0696e870d8e8b8cbf92587eecde0b87dec", "color": "rgb(47 157 36)"}, {"x": 6.00613260269165, "y": 0.48828122662598616, "startSeconds": 2.902494192123413, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event20_3974f1c21ad059f1393d9a5fd9127e190138106d", "color": "rgb(0 113 78)"}, {"x": 6.030396938323975, "y": 0.4921874947285687, "startSeconds": 2.9257142543792725, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event21_ebda11ad2f0a3664495072239f8a1c92dc2c9091", "color": "rgb(5 124 90)"}, {"x": 5.365604400634766, "y": 0.4374999819447112, "startSeconds": 2.600634813308716, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event22_70f6e8f6e96d408d2c10751b8703b50359d9e0ad", "color": "rgb(73 153 101)"}, {"x": 5.446662902832031, "y": 0.4374999819447112, "startSeconds": 2.600634813308716, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event23_d871998b34fc1a41f803c9c59f96b361132eb3d7", "color": "rgb(69 151 101)"}, {"x": 5.591134548187256, "y": 0.4374999819447112, "startSeconds": 2.600634813308716, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event24_f6d2eb667d68f9dd7b750279b082438e3483c170", "color": "rgb(39 126 68)"}, {"x": 5.6947832107543945, "y": 0.4374999819447112, "startSeconds": 2.600634813308716, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event25_2268ca3646827b85bd29d6d474a8376fa3cbe1f5", "color": "rgb(20 98 36)"}, {"x": 5.918614387512207, "y": 0.3671874769679562, "startSeconds": 2.18267560005188, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event26_f70e4fe8a4cdef9c9b9a7173810bc83b94028786", "color": "rgb(42 162 45)"}, {"x": 5.377236366271973, "y": 0.3261718624344212, "startSeconds": 1.938866138458252, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event27_d57d7f050e1deb47d9ef1b334624b1848e403097", "color": "rgb(62 192 51)"}, {"x": 5.999662399291992, "y": 0.29296874399733497, "startSeconds": 1.7414965629577637, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event28_4f500473f2c9b149be53f2c10e8abc3ce0c829a6", "color": "rgb(35 176 20)"}, {"x": 5.303228855133057, "y": 0.23632811721654434, "startSeconds": 1.404807209968567, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event29_c2f7f68e6aeaaff770ed7d878741f93c125cf61c", "color": "rgb(48 154 18)"}, {"x": 5.72243070602417, "y": 0.0, "startSeconds": 0.0, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event30_2d770e69c190fde23ca4f1b55def2720c996b5a1", "color": "rgb(78 165 43)"}, {"x": 5.998506546020508, "y": 0.3710937450705387, "startSeconds": 2.2058956623077393, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event31_74fb967c198e333c608fcb34ccb6a1970ed0399a", "color": "rgb(39 139 39)"}]'>
            </scatter-plot>


<a id="Example 2"></a>
<h2>Example 2</h2>


<a id="Original Audio"></a>
<h3>Original Audio</h3>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/original_37178eb066e6ab9709663d7536794e8fe2cc9302"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Reconstruction"></a>
<h3>Reconstruction</h3>
<p>We mask the second half of the input audio to enable the streaming algorithm, so only the first half of the input audio is reproduced.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/reconstruction_807d878ba92a10ca27596d1010bbf5e8e4322235"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Decomposition"></a>
<h3>Decomposition</h3>
<p>We can see that while energy is removed at each step, removed segments do not map cleanly onto audio "events" as a human listener would typically conceive of them.  Future work will move toward fewer and more meaningul events via induced sparsity and/or clustering of events.</p>

<img class="full-width" src="https://iterative-decomposition-v3.s3.amazonaws.com/decomposition_3b250698a07e497a00fc0481590e12e22bb1eb6c" height="200"></img>


<a id="Randomized"></a>
<h3>Randomized</h3>

<p>Here, we generate random event vectors with the original event times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedevents_dc8d9435273ef3e06d8fd5b4802d17bcd80c6c78"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>

<p>Here we use the original event vectors, but generate random times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedtimes_7c7e6c4e8719c654ce7b2d2451e79471865aebd3"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Event Vectors"></a>
<h3>Event Vectors</h3>
<p>Different stopping conditions might be chosen during inference (e.g. norm of the residual) but during training, we remove energy for 32 steps.  Each event vector is of dimension 32.  The decoder generates an event from this vector, which is then scheduled.  </p>

<img class="" src="https://iterative-decomposition-v3.s3.amazonaws.com/latents_f35e1c00ef8ac7085b871b8e3555d23a5cbacd69" height="200"></img>


<a id="Event Scatterplot"></a>
<h3>Event Scatterplot</h3>
<p>Time is along the x-axis, and a 32D -&gt; 1D projection of event vectors using t-SNE constitutes the distribution along the y-axis.</p>

<scatter-plot 
                width="600" 
                height="300" 
                radius="0.01" 
                points='[{"x": -0.29258185625076294, "y": 0.003906249928320449, "startSeconds": 0.02321995422244072, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event0_584dba273b4c603aac17ded2a96738b18b3b8870", "color": "rgb(128 165 90)"}, {"x": 0.3562244176864624, "y": 0.060546874829014996, "startSeconds": 0.3599092960357666, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event1_8035a39e23b0483a631de5e9de5f4f1f87b77bd5", "color": "rgb(183 168 171)"}, {"x": 0.3343367874622345, "y": 0.060546874829014996, "startSeconds": 0.3599092960357666, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event2_fc4b91a808c8551fa47d6b73793e03345ae1ccb4", "color": "rgb(154 127 140)"}, {"x": 0.12184922397136688, "y": 0.11523437758569344, "startSeconds": 0.6849886775016785, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event3_c9773edba6ced694c39fecd830cbc73a83c5d626", "color": "rgb(206 128 247)"}, {"x": 0.2718140780925751, "y": 0.11523437758569344, "startSeconds": 0.6849886775016785, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event4_b59945ccdf6fec47a865fa3d9f155afb6875a06d", "color": "rgb(170 100 220)"}, {"x": 0.6712687015533447, "y": 0.16992188034237188, "startSeconds": 1.0100680589675903, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event5_c7b73a12297c80dba0d0971363c2266e86dcaac9", "color": "rgb(188 193 225)"}, {"x": 0.2105807363986969, "y": 0.11328124353440217, "startSeconds": 0.6733786463737488, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event6_aba99302c662779e8d10a76e5de482bf623ba5b6", "color": "rgb(71 51 145)"}, {"x": 0.37801146507263184, "y": 0.060546874829014996, "startSeconds": 0.3599092960357666, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event7_e18482c79bc5ae9742b1db018c3d09a33e23ac3b", "color": "rgb(131 116 125)"}, {"x": -0.49873584508895874, "y": 0.22460937307187123, "startSeconds": 1.3351473808288574, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event8_712ebdbbad9fcd2053103b5ee78f38c5f1502802", "color": "rgb(165 175 72)"}, {"x": 0.6501272916793823, "y": 0.16992188034237188, "startSeconds": 1.0100680589675903, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event9_39a14d4d15e4adf587d3389bfc63e0ca11322f5f", "color": "rgb(140 167 131)"}, {"x": 0.4476945102214813, "y": 0.0, "startSeconds": 0.0, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event10_1a329beb8e53de90ada8439588df23797c4cdb0b", "color": "rgb(118 107 92)"}, {"x": 0.4678938686847687, "y": 0.3359374925821612, "startSeconds": 1.9969160556793213, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event11_f668b8eb4f16bd58cd9d584b787e48d3422ae53b", "color": "rgb(84 71 157)"}, {"x": 0.2833893895149231, "y": 0.003906249928320449, "startSeconds": 0.02321995422244072, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event12_e4b6e512b1082aaee025b050cc222ac69d03e34f", "color": "rgb(133 160 121)"}, {"x": -0.18794089555740356, "y": 0.38085937521827873, "startSeconds": 2.2639455795288086, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event13_5156093c16f51cc299011ff026ddfd7f3a39f416", "color": "rgb(129 164 177)"}, {"x": 0.6195839047431946, "y": 0.3359374925821612, "startSeconds": 1.9969160556793213, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event14_6b41466f476d1800c61faad4df65096e2d08e9be", "color": "rgb(77 79 168)"}, {"x": 0.16540785133838654, "y": 0.47851559647824615, "startSeconds": 2.8444442749023438, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event15_c0af93dd51313403e60dd88c954da7dd12422628", "color": "rgb(96 101 102)"}, {"x": 0.5360463261604309, "y": 0.4980468567737262, "startSeconds": 2.9605441093444824, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event16_c01ba44fcda06d7a03d116e42d118748f68cf7e6", "color": "rgb(63 100 117)"}, {"x": 0.3948536515235901, "y": 0.433593753950845, "startSeconds": 2.5774149894714355, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event17_2cae5d9543c0099cad88656f0b172a37b8aa4bd2", "color": "rgb(38 24 19)"}, {"x": -0.2550112307071686, "y": 0.37890624116698746, "startSeconds": 2.252335548400879, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event18_c53db5f34593dd06d046d1fdf3fa1c21c17cdc2c", "color": "rgb(71 120 118)"}, {"x": 0.15474361181259155, "y": 0.2792968658013706, "startSeconds": 1.6602267026901245, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event19_304ab93b2a4772a50b5e23379cd2c65470d5648f", "color": "rgb(87 98 110)"}, {"x": 0.16641242802143097, "y": 0.2792968658013706, "startSeconds": 1.6602267026901245, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event20_2a37ccf625b489f2e48888b4d6dd8dbdab6d1d4a", "color": "rgb(87 83 102)"}, {"x": -0.37110191583633423, "y": 0.22460937307187123, "startSeconds": 1.3351473808288574, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event21_de5f6e556ce879450407ddb5bb02250515dec787", "color": "rgb(137 137 78)"}, {"x": 0.26782524585723877, "y": 0.20117186472816684, "startSeconds": 1.195827603340149, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event22_b002e06351c1b86018a480173aa50a6c9c7f5c4b", "color": "rgb(84 93 90)"}, {"x": 0.027889693155884743, "y": 0.2792968658013706, "startSeconds": 1.6602267026901245, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event23_f168cbab1e5e210e6023198c076ae1629c3f6ec4", "color": "rgb(95 97 109)"}, {"x": 0.0171134565025568, "y": 0.2792968658013706, "startSeconds": 1.6602267026901245, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event24_730950e0552c28089cdb3ee60aabfeb7abb2c1c8", "color": "rgb(80 108 114)"}, {"x": 0.3304973244667053, "y": 0.10156249938972906, "startSeconds": 0.6037188172340393, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event25_7097f90f465ae9b183f29a7fb73395ac98b62fc7", "color": "rgb(42 58 107)"}, {"x": 0.048050958663225174, "y": 0.47851559647824615, "startSeconds": 2.8444442749023438, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event26_a7bcd4d3217d2e1db5f258c03e4cc88ccee788be", "color": "rgb(121 135 165)"}, {"x": 0.34789231419563293, "y": 0.433593753950845, "startSeconds": 2.5774149894714355, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event27_6981916d6b2d919126cfba9943fe66c99994ec97", "color": "rgb(57 55 33)"}, {"x": 0.1823941469192505, "y": 0.039062500536601874, "startSeconds": 0.2321995496749878, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event28_06e7936ae834103577d8fe99b3ad2c32607b3dde", "color": "rgb(0 50 25)"}, {"x": -0.6020532250404358, "y": 0.39453123335988494, "startSeconds": 2.345215320587158, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event29_f6a2d0041b3f420f0e4f445e622cddf00dec7cf7", "color": "rgb(125 254 129)"}, {"x": -0.13780200481414795, "y": 0.14062499992633093, "startSeconds": 0.8359183669090271, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event30_0e85788bfd1a5bd7575b78bcb28bbb598a46ab04", "color": "rgb(71 153 57)"}, {"x": -0.035555850714445114, "y": 0.2519531294638, "startSeconds": 1.4976871013641357, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event31_b17d5b9249aec905bd61e4564f21066be7ae3fdb", "color": "rgb(86 139 162)"}]'>
            </scatter-plot>


<a id="Example 3"></a>
<h2>Example 3</h2>


<a id="Original Audio"></a>
<h3>Original Audio</h3>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/original_37c4038ddfa2be073f85545039582401eecd68df"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Reconstruction"></a>
<h3>Reconstruction</h3>
<p>We mask the second half of the input audio to enable the streaming algorithm, so only the first half of the input audio is reproduced.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/reconstruction_25e47ec64382a8bd3e570a8b7b43dc96492478f1"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Decomposition"></a>
<h3>Decomposition</h3>
<p>We can see that while energy is removed at each step, removed segments do not map cleanly onto audio "events" as a human listener would typically conceive of them.  Future work will move toward fewer and more meaningul events via induced sparsity and/or clustering of events.</p>

<img class="full-width" src="https://iterative-decomposition-v3.s3.amazonaws.com/decomposition_13bf6be9b20ecf030c062b32b440df5b0515e704" height="200"></img>


<a id="Randomized"></a>
<h3>Randomized</h3>

<p>Here, we generate random event vectors with the original event times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedevents_5c8244f00057c7319e869eb17d95871da98dcd67"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>

<p>Here we use the original event vectors, but generate random times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedtimes_bf1c3ca329212246a58b9aae92a8c846242723c6"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Event Vectors"></a>
<h3>Event Vectors</h3>
<p>Different stopping conditions might be chosen during inference (e.g. norm of the residual) but during training, we remove energy for 32 steps.  Each event vector is of dimension 32.  The decoder generates an event from this vector, which is then scheduled.  </p>

<img class="" src="https://iterative-decomposition-v3.s3.amazonaws.com/latents_5c23c590e74742a55b72474499eabc47e49f56ca" height="200"></img>


<a id="Event Scatterplot"></a>
<h3>Event Scatterplot</h3>
<p>Time is along the x-axis, and a 32D -&gt; 1D projection of event vectors using t-SNE constitutes the distribution along the y-axis.</p>

<scatter-plot 
                width="600" 
                height="300" 
                radius="0.01" 
                points='[{"x": -1.4591255187988281, "y": 0.24999999541250872, "startSeconds": 1.486077070236206, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event0_9654f7d3ff14ea90395c67743bc349283cc2d2b3", "color": "rgb(84 25 145)"}, {"x": -1.0846844911575317, "y": 0.2734375037562131, "startSeconds": 1.6253968477249146, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event1_c4ec7fe1ea612dcb464d1e5c1ac66e82cafd9637", "color": "rgb(88 71 103)"}, {"x": -0.8445594310760498, "y": 0.2734375037562131, "startSeconds": 1.6253968477249146, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event2_b5cf99fbf6126b4fa65dd71ab7f51b5a4ff4fb75", "color": "rgb(58 47 63)"}, {"x": -1.4961655139923096, "y": 0.14843749602277967, "startSeconds": 0.8823582530021667, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event3_0631ad5059412bf8c41d2caa1a7241c187936204", "color": "rgb(87 66 135)"}, {"x": -0.5075892210006714, "y": 0.12109374965802999, "startSeconds": 0.7198185920715332, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event4_bc72e9d2e078a51932ca2a30376a18361c232333", "color": "rgb(200 206 138)"}, {"x": -1.2520344257354736, "y": 0.24999999541250872, "startSeconds": 1.486077070236206, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event5_958bcac93473fb04c648d151e82253f34316d16b", "color": "rgb(93 45 132)"}, {"x": -0.5711342096328735, "y": 0.0957031273173925, "startSeconds": 0.5688889026641846, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event6_378d93bf1778fe108a145ae16e54797f4204e767", "color": "rgb(228 229 170)"}, {"x": -1.3393115997314453, "y": 0.24804686136121745, "startSeconds": 1.4744670391082764, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event7_a4bf0711e9b76a600a769497ef9f0e4192d26a12", "color": "rgb(97 76 148)"}, {"x": -1.5639278888702393, "y": 0.312500004292815, "startSeconds": 1.8575963973999023, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event8_cf0e823204d16e19f7f3dd039071778582b7b772", "color": "rgb(96 85 124)"}, {"x": -1.2025786638259888, "y": 0.3261718624344212, "startSeconds": 1.938866138458252, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event9_4f06fcee5541f62287d1187849f7620c15731c6b", "color": "rgb(83 105 94)"}, {"x": -1.2091093063354492, "y": 0.24609374736428435, "startSeconds": 1.4628571271896362, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event10_af5250a86672da18e9ce5c91d1c0ae321bbde040", "color": "rgb(121 135 146)"}, {"x": -1.3387471437454224, "y": 0.19921875073123374, "startSeconds": 1.1842176914215088, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event11_e7782ab58a7458ac26a194229608ed239a1422c3", "color": "rgb(126 62 92)"}, {"x": -0.49876904487609863, "y": 0.0957031273173925, "startSeconds": 0.5688889026641846, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event12_3600a51a8ec4d47a9c246d9f7b3da1003bdbae40", "color": "rgb(222 225 143)"}, {"x": -0.8172705173492432, "y": 0.19921875073123374, "startSeconds": 1.1842176914215088, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event13_5ff31879193c35c23a4ec6dcc5be9f00ed282a69", "color": "rgb(124 95 65)"}, {"x": -1.2379850149154663, "y": 0.03710937400569492, "startSeconds": 0.2205895632505417, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event14_a39775b951c270f116995a3266c4e3c26acadc2a", "color": "rgb(123 144 118)"}, {"x": -0.7457117438316345, "y": 0.021484374292413122, "startSeconds": 0.1277097463607788, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event15_75cd5f8d473db4547a8c375f66e2b7bed75ff5b0", "color": "rgb(148 169 144)"}, {"x": -1.0429582595825195, "y": 0.17968749043575372, "startSeconds": 1.0681178569793701, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event16_79afa456380cd12645d71db5243390a43044d3af", "color": "rgb(91 79 67)"}, {"x": -0.6542795300483704, "y": 0.3417968546273187, "startSeconds": 2.0317459106445312, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event17_231ee100ac70df575a299d9dc217a7637b5983f8", "color": "rgb(88 132 63)"}, {"x": -0.7030419707298279, "y": 0.45312497413760866, "startSeconds": 2.693514585494995, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event18_579b7c6dc98b7b2bf499f2af1dd63c4f5bd7eda2", "color": "rgb(182 213 137)"}, {"x": -1.4413492679595947, "y": 0.4023437294563337, "startSeconds": 2.391655206680298, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event19_8c18fea51ea87f25cb38542c19306a6f053eb735", "color": "rgb(130 120 110)"}, {"x": -1.564211130142212, "y": 0.2871093618978193, "startSeconds": 1.7066665887832642, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event20_3096a600d53516169025f92f32afb9029cc95ba7", "color": "rgb(46 28 89)"}, {"x": -0.6412256956100464, "y": 0.021484374292413122, "startSeconds": 0.1277097463607788, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event21_0b79b950a2c1a8f4f4837c662e59b42938da4470", "color": "rgb(151 208 139)"}, {"x": -0.367488294839859, "y": 0.47851559647824615, "startSeconds": 2.8444442749023438, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event22_7210e51b5c3c56465ba7c7ef4d32d884686843c2", "color": "rgb(207 254 161)"}, {"x": -0.6507222056388855, "y": 0.13085936977859092, "startSeconds": 0.7778684496879578, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event23_e5366fb65a370c5260a364cf4bc65777b89af8dd", "color": "rgb(146 156 82)"}, {"x": -0.9389298558235168, "y": 0.2988281260968506, "startSeconds": 1.7763265371322632, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event24_f9d841348edb53175f45162c6784ed5bb9f19919", "color": "rgb(70 70 30)"}, {"x": -0.6450945734977722, "y": 0.36523438302538125, "startSeconds": 2.1710658073425293, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event25_e3e9e093d319627da1b879bfff658510336c24f1", "color": "rgb(103 135 69)"}, {"x": -0.2936895489692688, "y": 0.0, "startSeconds": 0.0, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event26_e57d9caeb7f2de0b063eece44ef1efb8452aecc9", "color": "rgb(142 193 114)"}, {"x": -1.2173497676849365, "y": 0.423828123803105, "startSeconds": 2.519365072250366, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event27_74987c3aede42ce45a811e3a27dfc3f8851cfc97", "color": "rgb(156 142 104)"}, {"x": -1.475014328956604, "y": 0.4101562255527824, "startSeconds": 2.4380950927734375, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event28_46833c2ded459c012f0b1a4fc474813344ecfb6b", "color": "rgb(88 99 93)"}, {"x": -0.7790449857711792, "y": 0.3574218869289325, "startSeconds": 2.1246259212493896, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event29_24fc053ea04722dfe52eef1d77b418e319880335", "color": "rgb(88 141 71)"}, {"x": -0.8958247900009155, "y": 0.05078124969486453, "startSeconds": 0.30185940861701965, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event30_f32fa156992353c98ccb031d02bdbd64aa3cf7cc", "color": "rgb(148 213 130)"}, {"x": -0.5881161093711853, "y": 0.21093749487590685, "startSeconds": 1.2538775205612183, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event31_18695635668b5a7611cbc2074b055bccc343daf5", "color": "rgb(116 99 0)"}]'>
            </scatter-plot>


<a id="Example 4"></a>
<h2>Example 4</h2>


<a id="Original Audio"></a>
<h3>Original Audio</h3>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/original_f1a1399b9c9d424f676f8d4b637b289acdab150b"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Reconstruction"></a>
<h3>Reconstruction</h3>
<p>We mask the second half of the input audio to enable the streaming algorithm, so only the first half of the input audio is reproduced.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/reconstruction_214af517b59077064c9e216ca04964816b95f712"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Decomposition"></a>
<h3>Decomposition</h3>
<p>We can see that while energy is removed at each step, removed segments do not map cleanly onto audio "events" as a human listener would typically conceive of them.  Future work will move toward fewer and more meaningul events via induced sparsity and/or clustering of events.</p>

<img class="full-width" src="https://iterative-decomposition-v3.s3.amazonaws.com/decomposition_12d15b0cd0d86cdb54bcb957cd2420e553913c96" height="200"></img>


<a id="Randomized"></a>
<h3>Randomized</h3>

<p>Here, we generate random event vectors with the original event times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedevents_6691721a846b04dc7422be65cc27479f47bb5017"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>

<p>Here we use the original event vectors, but generate random times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedtimes_dddb66f7c09f434aa59212cc5b699b2dce92e271"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Event Vectors"></a>
<h3>Event Vectors</h3>
<p>Different stopping conditions might be chosen during inference (e.g. norm of the residual) but during training, we remove energy for 32 steps.  Each event vector is of dimension 32.  The decoder generates an event from this vector, which is then scheduled.  </p>

<img class="" src="https://iterative-decomposition-v3.s3.amazonaws.com/latents_fd6aa0657951c2455c0035bb23b5dee1ed03c07b" height="200"></img>


<a id="Event Scatterplot"></a>
<h3>Event Scatterplot</h3>
<p>Time is along the x-axis, and a 32D -&gt; 1D projection of event vectors using t-SNE constitutes the distribution along the y-axis.</p>

<scatter-plot 
                width="600" 
                height="300" 
                radius="0.01" 
                points='[{"x": 8.684721946716309, "y": 0.35937498087150743, "startSeconds": 2.1362357139587402, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event0_473dcfec186de21f9e2f18ab25d1b430e77ec1cf", "color": "rgb(79 64 114)"}, {"x": 8.768125534057617, "y": 0.4589843762914825, "startSeconds": 2.728344678878784, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event1_a864c607a0537e03235efe9d523397af9685a71a", "color": "rgb(131 14 57)"}, {"x": 9.118660926818848, "y": 0.3847656032121449, "startSeconds": 2.287165403366089, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event2_8e602ce63565a4dc85bee9a6818cded511872e09", "color": "rgb(137 130 141)"}, {"x": 9.323211669921875, "y": 0.4667968723879312, "startSeconds": 2.774784564971924, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event3_365b653a05169cb00ca0aefa6e2d4b59905ceb51", "color": "rgb(159 78 82)"}, {"x": 8.563891410827637, "y": 0.07617187203550202, "startSeconds": 0.4527890980243683, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event4_4543ec88ca4f25ac103db2b17e6ba0546f157891", "color": "rgb(129 110 139)"}, {"x": 8.609344482421875, "y": 0.07812500107320375, "startSeconds": 0.4643990993499756, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event5_e995506ef160a743d3c6ac8b85d0244af0643e6b", "color": "rgb(126 110 119)"}, {"x": 8.574284553527832, "y": 0.08593749716965249, "startSeconds": 0.5108389854431152, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event6_0482ef0d7f75a4194785195dcb940c04e8343a13", "color": "rgb(132 109 112)"}, {"x": 8.755858421325684, "y": 0.09179686924198904, "startSeconds": 0.54566890001297, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event7_c915ec29e379668757c6e5479574c9ff8b6b4b27", "color": "rgb(141 144 128)"}, {"x": 8.867056846618652, "y": 0.12109374965802999, "startSeconds": 0.7198185920715332, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event8_50f73524350cf14fa46bce93797eafaac5976af2", "color": "rgb(178 110 164)"}, {"x": 8.833569526672363, "y": 0.13867187590221874, "startSeconds": 0.8243083953857422, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event9_28ae6d07342c23243f6d0c18ed6a4bec229cdcf4", "color": "rgb(189 126 186)"}, {"x": 8.98498249053955, "y": 0.18554687253526936, "startSeconds": 1.1029478311538696, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event10_2884d29d4450b6e855fbe085d3c6a4700847e4fa", "color": "rgb(201 155 227)"}, {"x": 9.032115936279297, "y": 0.19921875073123374, "startSeconds": 1.1842176914215088, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event11_30216adae19ecb10ea5e9b864f9a02affdde2414", "color": "rgb(166 123 173)"}, {"x": 9.06959342956543, "y": 0.2187499909723556, "startSeconds": 1.300317406654358, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event12_cef62a4344c98e7d00418b45051bcabb53fe1dda", "color": "rgb(118 78 138)"}, {"x": 9.151968002319336, "y": 0.2402343652647687, "startSeconds": 1.4280271530151367, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event13_ea268061e672b73a36b978ea548f0f37df63d43a", "color": "rgb(128 89 177)"}, {"x": 8.934395790100098, "y": 0.1933593686317181, "startSeconds": 1.1493877172470093, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event14_95cded308a7560119a7b250aba13257a78a9dc6b", "color": "rgb(173 126 199)"}, {"x": 8.680731773376465, "y": 0.1562500021464075, "startSeconds": 0.9287981986999512, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event15_adc9eb93948c5fe387596edda72245549bdf34e0", "color": "rgb(211 205 254)"}, {"x": 8.427128791809082, "y": 0.0, "startSeconds": 0.0, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event16_238f6e7294f6518d070d4c6b3f93cc47a8fbbf12", "color": "rgb(98 52 114)"}, {"x": 8.480668067932129, "y": 0.003906249928320449, "startSeconds": 0.02321995422244072, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event17_85220b15853c1ac5b1e5dd8ca0ea5ba99a86f4e9", "color": "rgb(78 41 92)"}, {"x": 8.28908920288086, "y": 0.06249999885312718, "startSeconds": 0.3715192675590515, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event18_c607ec78fb7a9ff240f845571da6a8374bb94fc3", "color": "rgb(114 54 125)"}, {"x": 8.995931625366211, "y": 0.2636718736084731, "startSeconds": 1.5673469305038452, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event19_2c2a35b758ccf38ffe12e2cf4af2fe6aa4818c08", "color": "rgb(126 72 152)"}, {"x": 8.308853149414062, "y": 0.015624999713281795, "startSeconds": 0.09287981688976288, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event20_3de8dad7a0e527f90493d29a2cc1fc994a8573bb", "color": "rgb(38 9 95)"}, {"x": 9.246487617492676, "y": 0.3007812400937837, "startSeconds": 1.7879364490509033, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event21_3a75a95ad10c26f4468e44c17b97a4c3faf7fe1a", "color": "rgb(156 138 197)"}, {"x": 8.905122756958008, "y": 0.3359374925821612, "startSeconds": 1.9969160556793213, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event22_27c99c577b0bc1c4564b6766ec739c1dd73b36fc", "color": "rgb(51 77 93)"}, {"x": 9.29587173461914, "y": 0.4804687305295374, "startSeconds": 2.8560543060302734, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event23_7046dee68fd469f91b3846bf5c0da7ccc286cb94", "color": "rgb(133 55 65)"}, {"x": 9.042535781860352, "y": 0.2773437518044375, "startSeconds": 1.6486167907714844, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event24_8819515d0d44e03dd7436aeee7e885e05f78230f", "color": "rgb(157 88 171)"}, {"x": 9.402612686157227, "y": 0.32226561438619683, "startSeconds": 1.9156461954116821, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event25_9a034a6bfbca91e53ac98a3ac6c46adf9d677854", "color": "rgb(48 115 94)"}, {"x": 8.170121192932129, "y": 0.005859374579131327, "startSeconds": 0.03482992947101593, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event26_f9ca52b648b19a92245eaced81b5328ef0656538", "color": "rgb(51 0 132)"}, {"x": 8.7793550491333, "y": 0.39062500536601874, "startSeconds": 2.321995496749878, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event27_3330ad53bccdc7ac534cbbd108f5a5c243fa0ec0", "color": "rgb(106 98 106)"}, {"x": 8.489112854003906, "y": 0.4316406198995537, "startSeconds": 2.565804958343506, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event28_99ec68110f79fb50353fb04868239f0ee7a786b8", "color": "rgb(134 49 74)"}, {"x": 9.323786735534668, "y": 0.32226561438619683, "startSeconds": 1.9156461954116821, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event29_ddb389512701ea18ccfb2367cc2f978e1c91436c", "color": "rgb(34 101 91)"}, {"x": 8.790731430053711, "y": 0.11914062563391781, "startSeconds": 0.7082086205482483, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event30_17095b1e9300a14fcc053c392a89518407ca62a0", "color": "rgb(165 97 148)"}, {"x": 9.420198440551758, "y": 0.4980468567737262, "startSeconds": 2.9605441093444824, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event31_ed4ce36e881ee1a6cf14f24448b9b9d1c324c8af", "color": "rgb(120 116 103)"}]'>
            </scatter-plot>


<a id="Example 5"></a>
<h2>Example 5</h2>


<a id="Original Audio"></a>
<h3>Original Audio</h3>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/original_b7dfbd6651d413209bd9045a41ff9bc3663f572a"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Reconstruction"></a>
<h3>Reconstruction</h3>
<p>We mask the second half of the input audio to enable the streaming algorithm, so only the first half of the input audio is reproduced.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/reconstruction_1f93edb8f5a2a9c35a041f1a0d374ab7fff5be7a"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Decomposition"></a>
<h3>Decomposition</h3>
<p>We can see that while energy is removed at each step, removed segments do not map cleanly onto audio "events" as a human listener would typically conceive of them.  Future work will move toward fewer and more meaningul events via induced sparsity and/or clustering of events.</p>

<img class="full-width" src="https://iterative-decomposition-v3.s3.amazonaws.com/decomposition_0f7192103c1d764e8024d1f24d9ff81a3c6467b2" height="200"></img>


<a id="Randomized"></a>
<h3>Randomized</h3>

<p>Here, we generate random event vectors with the original event times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedevents_09de406d7f6a55472ed91b75f7e15c3d6089258a"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>

<p>Here we use the original event vectors, but generate random times.</p>

<audio-view
            src="https://iterative-decomposition-v3.s3.amazonaws.com/randomizedtimes_b97102e52573d0bdb4a1517e55d9a551e0e99cb9"
            height="100"
            samples="256"
            scale="1"
            controls
        ></audio-view>


<a id="Event Vectors"></a>
<h3>Event Vectors</h3>
<p>Different stopping conditions might be chosen during inference (e.g. norm of the residual) but during training, we remove energy for 32 steps.  Each event vector is of dimension 32.  The decoder generates an event from this vector, which is then scheduled.  </p>

<img class="" src="https://iterative-decomposition-v3.s3.amazonaws.com/latents_5007552ab94c7ca540c2059224bf295843350f25" height="200"></img>


<a id="Event Scatterplot"></a>
<h3>Event Scatterplot</h3>
<p>Time is along the x-axis, and a 32D -&gt; 1D projection of event vectors using t-SNE constitutes the distribution along the y-axis.</p>

<scatter-plot 
                width="600" 
                height="300" 
                radius="0.01" 
                points='[{"x": 10.362907409667969, "y": 0.16015625019463187, "startSeconds": 0.952018141746521, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event0_5849f9abf727eb3f46c5782a28d0a21bcc52a17f", "color": "rgb(33 151 132)"}, {"x": 10.401444435119629, "y": 0.16601562226696842, "startSeconds": 0.9868480563163757, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event1_7e69b140c2cd6c474f27258129575958649d49a9", "color": "rgb(73 147 128)"}, {"x": 10.68169116973877, "y": 0.17578124238752935, "startSeconds": 1.0448979139328003, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event2_4a70f7cf3f12d6fd3e9d0ed5043d95b7d6b532b5", "color": "rgb(62 117 103)"}, {"x": 10.8345947265625, "y": 0.18945312058349373, "startSeconds": 1.1261677742004395, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event3_6e58d95364ba289f336f5fc65b6f44e4a6f12380", "color": "rgb(91 91 98)"}, {"x": 10.659238815307617, "y": 0.21289062892719812, "startSeconds": 1.265487551689148, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event4_5ac26a4450b6a1b1ac64027d9ce694822681e1ed", "color": "rgb(123 139 151)"}, {"x": 10.764842987060547, "y": 0.24414061331299308, "startSeconds": 1.4512470960617065, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event5_cf18efad230ef7f5820846d4839956e4b3a16517", "color": "rgb(72 193 140)"}, {"x": 10.240632057189941, "y": 0.2695312356536306, "startSeconds": 1.6021767854690552, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event6_21c6bdf8f457c970c377cc430e5850d68a282d59", "color": "rgb(23 187 103)"}, {"x": 10.073936462402344, "y": 0.2890624959491106, "startSeconds": 1.7182766199111938, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event7_e5dfff54c37a9e35476db1af5ca3dc26820c648f", "color": "rgb(81 190 134)"}, {"x": 10.013976097106934, "y": 0.2910156099460437, "startSeconds": 1.729886531829834, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event8_ae8d442ed3ecf0368ffce9288bdf38abae237543", "color": "rgb(75 193 132)"}, {"x": 10.103034019470215, "y": 0.2988281260968506, "startSeconds": 1.7763265371322632, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event9_628ae9f122629e6933f45baacc52fe79be274c03", "color": "rgb(36 178 138)"}, {"x": 10.278618812561035, "y": 0.3007812400937837, "startSeconds": 1.7879364490509033, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event10_747e95b5db8c46917e91cec6856d6334d6e2c023", "color": "rgb(41 178 139)"}, {"x": 10.891427040100098, "y": 0.33007811048264557, "startSeconds": 1.9620860815048218, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event11_27e6bba1d901714f606fa04bf2fce3e418975efa", "color": "rgb(128 187 190)"}, {"x": 10.654735565185547, "y": 0.3359374925821612, "startSeconds": 1.9969160556793213, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event12_de1403b20ea950468144c6db94bf70e140e5e30d", "color": "rgb(85 202 180)"}, {"x": 10.253622055053711, "y": 0.35937498087150743, "startSeconds": 2.1362357139587402, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event13_8ecd358df3ef0b3cd0870c1068938d0118b7aa48", "color": "rgb(80 254 190)"}, {"x": 10.84432315826416, "y": 0.38281250926957, "startSeconds": 2.2755556106567383, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event14_9e3c6fb157deecf26754432ef99bf3e4eb03358b", "color": "rgb(89 137 156)"}, {"x": 10.418771743774414, "y": 0.3984375014624675, "startSeconds": 2.3684353828430176, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event15_b9f825c33a2d3dfb69aa81dfe0721dd93a44ef46", "color": "rgb(48 134 166)"}, {"x": 10.412202835083008, "y": 0.3984375014624675, "startSeconds": 2.3684353828430176, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event16_14e0b47df51ab3a57758f4240f51c2b839eec7f9", "color": "rgb(41 109 135)"}, {"x": 10.217432022094727, "y": 0.41406249365536496, "startSeconds": 2.461315155029297, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event17_ac7655058d63a04c80b5b3ab5412a65fbbafc331", "color": "rgb(0 128 115)"}, {"x": 10.87777328491211, "y": 0.18749998653220246, "startSeconds": 1.1145577430725098, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event18_a2b0113974a0790d84f71e5b0119b01b52b1180b", "color": "rgb(72 74 89)"}, {"x": 10.940230369567871, "y": 0.12499999770625436, "startSeconds": 0.743038535118103, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event19_3e54205f1fa5f076cef28180d9344a1cd23ed414", "color": "rgb(54 74 105)"}, {"x": 10.911652565002441, "y": 0.12499999770625436, "startSeconds": 0.743038535118103, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event20_dfcdb9c3c7590da801ef257698fd66c26a013034", "color": "rgb(54 84 103)"}, {"x": 10.802895545959473, "y": 0.12695312173036655, "startSeconds": 0.7546485066413879, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event21_78d5e770517005a1b9eea5e435a72f3bb9737f5f", "color": "rgb(53 116 119)"}, {"x": 11.17082691192627, "y": 0.0546874977430889, "startSeconds": 0.3250793516635895, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event22_aa36de0abae4cae20cc4a60a94bb01f61b110a41", "color": "rgb(144 106 167)"}, {"x": 11.19856071472168, "y": 0.09765625134150469, "startSeconds": 0.5804988741874695, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event23_4fbf6a95077a6bf4fd17b8aa4992d26041ad0241", "color": "rgb(65 26 84)"}, {"x": 10.79133129119873, "y": 0.07031249996316546, "startSeconds": 0.41795918345451355, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event24_2a3f5c1d8816aff56d187936910aa12080f19fd5", "color": "rgb(142 155 176)"}, {"x": 10.640951156616211, "y": 0.07031249996316546, "startSeconds": 0.41795918345451355, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event25_bd46ef904e0a0393d5572f18cc6a29ee2eb6ee35", "color": "rgb(118 207 183)"}, {"x": 10.113205909729004, "y": 0.30859373619023245, "startSeconds": 1.834376335144043, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event26_737b135ce6571f03f39f4c4540e2cedef34e1421", "color": "rgb(19 186 114)"}, {"x": 10.043378829956055, "y": 0.4472656120924512, "startSeconds": 2.658684730529785, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event27_ecad49ba6fffe7569b78f2f641a1031b35f0155e", "color": "rgb(9 245 153)"}, {"x": 10.32706069946289, "y": 0.4980468567737262, "startSeconds": 2.9605441093444824, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event28_2b22305daf9cf6177fd73752f23caf453ca3ff2c", "color": "rgb(104 221 198)"}, {"x": 11.214534759521484, "y": 0.25585937751202437, "startSeconds": 1.5209070444107056, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event29_1e64082bf86d2a67d91765e2ceae2015150f432d", "color": "rgb(72 142 156)"}, {"x": 11.412583351135254, "y": 0.04492187260893843, "startSeconds": 0.26702946424484253, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event30_08ec6ef50ab5f9a770192674f4e93650d8f390e2", "color": "rgb(119 97 162)"}, {"x": 11.127824783325195, "y": 0.02734374887154445, "startSeconds": 0.16253967583179474, "duration_seconds": 0, "url": "https://iterative-decomposition-v3.s3.amazonaws.com/event31_5ae322f781853a431c369d44d7e6e19c4e5cef67", "color": "rgb(126 149 177)"}]'>
            </scatter-plot>

<code-block language="python">n_samples = 2 ** 17

samples_per_event = 2048



# this is cut in half since we'll mask out the second half of encoder activations

n_events = (n_samples // samples_per_event) // 2

context_dim = 32



# the samplerate, in hz, of the audio signal

samplerate = 22050



# derived, the total number of seconds of audio

n_seconds = n_samples / samplerate



transform_window_size = 2048

transform_step_size = 256



n_frames = n_samples // transform_step_size



from argparse import ArgumentParser

from typing import Dict, Tuple



import numpy as np

import torch

from sklearn.manifold import TSNE

from torch import nn



from conjure import S3Collection, \

    conjure_article, CitationComponent, AudioComponent, ImageComponent, \

    CompositeComponent, Logger, ScatterPlotComponent

from data import get_one_audio_segment, AudioIterator

from iterativedecomposition import Model as IterativeDecompositionModel

from modules.eventgenerators.overfitresonance import OverfitResonanceModel

from modules import max_norm, sparse_softmax



remote_collection_name = 'iterative-decomposition-v3'





def to_numpy(x: torch.Tensor):

    return x.data.cpu().numpy()





# thanks to https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/9

def count_parameters(model):

    return sum(p.numel() for p in model.parameters() if p.requires_grad)





def process_events(

        vectors: torch.Tensor,

        times: torch.Tensor,

        total_seconds: float) -> Tuple:

    positions = torch.argmax(times, dim=-1, keepdim=True) / times.shape[-1]

    times = [float(x) for x in (positions * total_seconds).view(-1).data.cpu().numpy()]



    normalized = vectors.data.cpu().numpy().reshape((-1, context_dim))

    normalized = normalized - normalized.min(axis=0, keepdims=True)

    normalized = normalized / (normalized.max(axis=0, keepdims=True) + 1e-8)

    tsne = TSNE(n_components=1)

    points = tsne.fit_transform(normalized)



    proj = np.random.uniform(0, 1, (context_dim, 3))

    colors = normalized @ proj

    colors -= colors.min()

    colors /= (colors.max() + 1e-8)

    colors *= 255

    colors = colors.astype(np.uint8)

    colors = [f'rgb({c[0]} {c[1]} {c[2]})' for c in colors]



    t = np.array(times) / total_seconds

    points = np.concatenate([points.reshape((-1, 1)), t.reshape((-1, 1))], axis=-1)



    return points, times, colors





def load_model(wavetable_device: str = 'cpu') -> nn.Module:

    hidden_channels = 512



    model = IterativeDecompositionModel(

        in_channels=1024,

        hidden_channels=hidden_channels,

        resonance_model=OverfitResonanceModel(

            n_noise_filters=64,

            noise_expressivity=4,

            noise_filter_samples=128,

            noise_deformations=32,

            instr_expressivity=4,

            n_events=1,

            n_resonances=4096,

            n_envelopes=64,

            n_decays=64,

            n_deformations=64,

            n_samples=n_samples,

            n_frames=n_frames,

            samplerate=samplerate,

            hidden_channels=hidden_channels,

            wavetable_device=wavetable_device,

            fine_positioning=True,

            fft_resonance=True

        ))



    with open('iterativedecomposition9.dat', 'rb') as f:

        model.load_state_dict(torch.load(f, map_location=lambda storage, loc: storage))



    print('Total parameters', count_parameters(model))

    print('Encoder parameters', count_parameters(model.encoder))

    print('Decoder parameters', count_parameters(model.resonance))



    return model





def scatterplot_section(logger: Logger) -> ScatterPlotComponent:

    model = load_model()

    ai = AudioIterator(

        batch_size=4,

        n_samples=n_samples,

        samplerate=22050,

        normalize=True,

        as_torch=True)



    batch = next(iter(ai))

    batch = batch.view(-1, 1, n_samples).to('cpu')

    events, vectors, times = model.iterative(batch)



    total_seconds = n_samples / samplerate



    points, times, colors = process_events(vectors, times, total_seconds)



    events = events.view(-1, n_samples)



    events = {f'event{i}': events[i: i + 1, :] for i in range(events.shape[0])}



    scatterplot_srcs = []



    event_components = {}

    for k, v in events.items():

        _, e = logger.log_sound(k, v)

        scatterplot_srcs.append(e.public_uri)

        event_components[k] = AudioComponent(e.public_uri, height=35, controls=False)



    scatterplot_component = ScatterPlotComponent(

        scatterplot_srcs,

        width=800,

        height=400,

        radius=0.01,

        points=points,

        times=times,

        colors=colors, )



    return scatterplot_component





def generate_multiple_events(

        model: nn.Module,

        vectors: torch.Tensor,

        times: torch.Tensor) -> torch.Tensor:

    generation_result = torch.cat(

        [model.generate(vectors[:, i:i + 1, :], times[:, i:i + 1, :]) for i in range(n_events)], dim=1)



    generation_result = torch.sum(generation_result, dim=1, keepdim=True)

    generation_result = max_norm(generation_result)

    return generation_result





def generate(

        model: nn.Module,

        vectors: torch.Tensor,

        times: torch.Tensor,

        randomize_events: bool,

        randomize_times: bool) -> torch.Tensor:

    batch, n_events, _ = vectors.shape



    if randomize_events:

        vectors = torch.zeros_like(vectors).uniform_(vectors.min().item(), vectors.max().item())



    if randomize_times:

        times = torch.zeros_like(times).uniform_(-1, 1)

        times = sparse_softmax(times, dim=-1, normalize=True) * times



    generation_result = generate_multiple_events(model, vectors, times)

    return generation_result





def streaming_section(logger: Logger) -> CompositeComponent:

    model = load_model()

    samples = get_one_audio_segment(n_samples * 4, samplerate, device='cpu').view(1, 1, -1)



    with torch.no_grad():

        recon = model.streaming(samples)

        recon = max_norm(recon)



    _, orig = logger.log_sound(key='streamingorig', audio=samples)

    orig = AudioComponent(orig.public_uri, height=100, controls=True, scale=4)



    _, recon = logger.log_sound(key='streamingrecon', audio=recon)

    recon = AudioComponent(recon.public_uri, height=100, controls=True, scale=4)



    return CompositeComponent(

        orig=orig,

        recon=recon,

    )





def reconstruction_section(logger: Logger) -> CompositeComponent:

    model = load_model()



    # get a random audio segment

    samples = get_one_audio_segment(n_samples, samplerate, device='cpu').view(1, 1, n_samples)

    events, vectors, times, residuals = model.iterative(samples, return_all_residuals=True)



    residuals = residuals.view(n_events, 1024, -1).data.cpu().numpy()

    residuals = residuals[:, ::-1, :]

    print('RESIDUAL', residuals.min(), residuals.max())

    residuals = np.log(residuals + 1e-6)

    t = residuals.shape[-1]

    residuals = residuals[..., :t // 2]



    _, movie = logger.log_movie('decomposition', residuals, fps=2)

    movie = ImageComponent(movie.public_uri, height=200, title='decomposition')



    # generate audio with the same times, but randomized event vectors

    randomized_events = generate(model, vectors, times, randomize_events=True, randomize_times=False)

    _, random_events = logger.log_sound('randomizedevents', randomized_events)

    random_events_component = AudioComponent(random_events.public_uri, height=100, controls=True)



    # generate audio with the same events, but randomized times

    randomized_times = generate(model, vectors, times, randomize_events=False, randomize_times=True)

    _, random_times = logger.log_sound('randomizedtimes', randomized_times)

    random_times_component = AudioComponent(random_times.public_uri, height=100, controls=True)



    total_seconds = n_samples / samplerate



    points, times, colors = process_events(vectors, times, total_seconds)



    # sum together all events

    summed = torch.sum(events, dim=1, keepdim=True)

    summed = max_norm(summed)



    _, original = logger.log_sound(f'original', samples)

    _, reconstruction = logger.log_sound(f'reconstruction', summed)



    orig_audio_component = AudioComponent(original.public_uri, height=100)

    recon_audio_component = AudioComponent(reconstruction.public_uri, height=100)



    events = {f'event{i}': events[:, i: i + 1, :] for i in range(events.shape[1])}



    scatterplot_srcs = []



    event_components = {}

    for k, v in events.items():

        _, e = logger.log_sound(k, v)

        scatterplot_srcs.append(e.public_uri)

        event_components[k] = AudioComponent(e.public_uri, height=15, controls=False)



    scatterplot_component = ScatterPlotComponent(

        scatterplot_srcs,

        width=600,

        height=300,

        radius=0.01,

        points=points,

        times=times,

        colors=colors, )



    _, event_vectors = logger.log_matrix_with_cmap('latents', vectors[0].T, cmap='viridis')

    latents = ImageComponent(event_vectors.public_uri, height=200, title='latent event vectors', full_width=False)



    composite = CompositeComponent(

        orig_audio=orig_audio_component,

        recon_audio=recon_audio_component,

        latents=latents,

        scatterplot=scatterplot_component,

        random_events=random_events_component,

        random_times=random_times_component,

        decomposition=movie,

        **event_components

    )



    return composite</code-block>


<a id="Notes"></a>
<h1>Notes</h1>
<p>This blog post is generated from a
<a href="https://github.com/JohnVinyard/matching-pursuit/blob/main/v3blogpost.py">Python script</a> using
<a href="https://github.com/JohnVinyard/conjure">conjure</a>.</p>

<code-block language="python">def demo_page_dict() -> Dict[str, any]:

    print(f'Generating article...')



    remote = S3Collection(

        remote_collection_name, is_public=True, cors_enabled=True)



    logger = Logger(remote)



    # print('Creating large scatterplot')

    # large_scatterplot = scatterplot_section(logger)



    print('Creating streaming section')

    streaming = streaming_section(logger)



    print('Creating reconstruction examples')

    example_1 = reconstruction_section(logger)

    example_2 = reconstruction_section(logger)

    example_3 = reconstruction_section(logger)

    example_4 = reconstruction_section(logger)

    example_5 = reconstruction_section(logger)



    citation = CitationComponent(

        tag='johnvinyarditerativedecompositionv3',

        author='Vinyard, John',

        url='https://blog.cochlea.xyz/sparse-interpretable-audio-codec-paper.html',

        header='Toward a Sparse Interpretable Audio Codec',

        year='2025',

    )



    return dict(

        streaming=streaming,

        example_1=example_1,

        example_2=example_2,

        example_3=example_3,

        example_4=example_4,

        example_5=example_5,

        citation=citation

    )





def generate_demo_page():

    display = demo_page_dict()

    conjure_article(

        __file__,

        'html',

        title='Toward a Sparse Interpretable Audio Codec',

        **display)





if __name__ == '__main__':

    parser = ArgumentParser()



    parser.add_argument('--clear', action='store_true')

    parser.add_argument('--list', action='store_true')



    args = parser.parse_args()



    if args.list:

        remote = S3Collection(

            remote_collection_name, is_public=True, cors_enabled=True)

        print(remote)

        print('Listing stored keys')

        for key in remote.iter_prefix(start_key=b'', prefix=b''):

            print(key)



    if args.clear:

        remote = S3Collection(

            remote_collection_name, is_public=True, cors_enabled=True)

        remote.destroy(prefix=b'')



    generate_demo_page()</code-block>


                <a href="#">
                    <div class="back-to-top">
                        Back to Top
                    </div>
                </a>

            </body>
            </html>
    